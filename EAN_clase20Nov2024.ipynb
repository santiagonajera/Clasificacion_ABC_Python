{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPHrEB5q+AD56xExcYbrsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagonajera/Clasificacion_ABC_Python/blob/main/EAN_clase20Nov2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7Bsn6P5P3CEi",
        "outputId": "acfb0441-40dd-43f5-f8a6-0528f02fc2ee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['SKU'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-46ae9875960f>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Mostrar el resultado final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total_Value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cumulative_Percentage'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ABC_Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['SKU'] not in index\""
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# URL del archivo Excel\n",
        "url = 'https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx'\n",
        "\n",
        "# Cargar los datos de las cuatro hojas del archivo Excel\n",
        "lead_time = pd.read_excel(url, sheet_name='LeadTime-Dias')\n",
        "historico = pd.read_excel(url, sheet_name='Historico')\n",
        "forecast = pd.read_excel(url, sheet_name='Forecast')\n",
        "precios_costos = pd.read_excel(url, sheet_name='Precios-Costos')\n",
        "\n",
        "# Función personalizada para convertir columnas a tipo numérico\n",
        "def convert_to_numeric(df, exclude_columns=['SKU']):\n",
        "    for col in df.columns:\n",
        "        if col not in exclude_columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "    return df\n",
        "\n",
        "# Limpiar y preparar los datos\n",
        "lead_time = convert_to_numeric(lead_time)\n",
        "historico = convert_to_numeric(historico)\n",
        "forecast = convert_to_numeric(forecast)\n",
        "precios_costos = convert_to_numeric(precios_costos)\n",
        "\n",
        "# Seleccionar solo las columnas numéricas para los cálculos posteriores\n",
        "lead_time = lead_time.select_dtypes(include=[np.number])\n",
        "historico = historico.select_dtypes(include=[np.number])\n",
        "forecast = forecast.select_dtypes(include=[np.number])\n",
        "precios_costos = precios_costos.select_dtypes(include=[np.number])\n",
        "\n",
        "# Clasificación ABC\n",
        "# Calcular el valor total multiplicando la suma de las ventas pronosticadas por el precio\n",
        "forecast['Total_Value'] = forecast.sum(axis=1) * precios_costos['Precio']\n",
        "\n",
        "# Calcular el porcentaje acumulado\n",
        "forecast['Cumulative_Percentage'] = forecast['Total_Value'].cumsum() / forecast['Total_Value'].sum() * 100\n",
        "\n",
        "# Asignar categorías A (0-60%), B (60-80%), C (80-100%)\n",
        "def assign_abc_category(percentage):\n",
        "    if percentage <= 60:\n",
        "        return 'A'\n",
        "    elif percentage <= 80:\n",
        "        return 'B'\n",
        "    else:\n",
        "        return 'C'\n",
        "\n",
        "forecast['ABC_Category'] = forecast['Cumulative_Percentage'].apply(assign_abc_category)\n",
        "\n",
        "# Mostrar el resultado final\n",
        "print(forecast[['SKU', 'Total_Value', 'Cumulative_Percentage', 'ABC_Category']])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Función para convertir columnas a tipo numérico y llenar NaN con 0\n",
        "def convert_to_numeric_and_fillna(column):\n",
        "    return pd.to_numeric(column, errors='coerce').fillna(0)\n",
        "\n",
        "# Cargar los datos de las cuatro hojas del archivo Excel\n",
        "url = \"https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx\"\n",
        "\n",
        "# Cargar cada hoja en un DataFrame\n",
        "df_leadtime = pd.read_excel(url, sheet_name='LeadTime-Dias')\n",
        "df_historico = pd.read_excel(url, sheet_name='Historico')\n",
        "df_forecast = pd.read_excel(url, sheet_name='Forecast')\n",
        "df_precios = pd.read_excel(url, sheet_name='Precios-Costos')\n",
        "\n",
        "# Limpiar y preparar los datos\n",
        "# Convertir columnas a tipo numérico y llenar NaN con 0\n",
        "for df in [df_leadtime, df_historico, df_forecast, df_precios]:\n",
        "    for col in df.columns:\n",
        "        if col != 'SKU':\n",
        "            df[col] = convert_to_numeric_and_fillna(df[col])\n",
        "\n",
        "# Seleccionar solo las columnas numéricas para los cálculos posteriores\n",
        "df_leadtime = df_leadtime.select_dtypes(include=[np.number])\n",
        "df_historico = df_historico.select_dtypes(include=[np.number])\n",
        "df_forecast = df_forecast.select_dtypes(include=[np.number])\n",
        "df_precios = df_precios.select_dtypes(include=[np.number])\n",
        "\n",
        "# Clasificación ABC\n",
        "# Calcular el valor total multiplicando la suma de las ventas pronosticadas por el precio\n",
        "df_forecast['Total_Value'] = df_forecast.sum(axis=1) * df_precios.iloc[:, 0]\n",
        "\n",
        "# Calcular el porcentaje acumulado\n",
        "df_forecast['Cumulative_Percentage'] = df_forecast['Total_Value'].cumsum() / df_forecast['Total_Value'].sum() * 100\n",
        "\n",
        "# Asignar categorías ABC\n",
        "df_forecast['ABC_Category'] = pd.cut(df_forecast['Cumulative_Percentage'], bins=[0, 60, 80, 100], labels=['A', 'B', 'C'])\n",
        "\n",
        "# Clasificación XYZ\n",
        "# Calcular la desviación estándar de las ventas históricas\n",
        "df_historico['Std_Dev'] = df_historico.std(axis=1)\n",
        "\n",
        "# Calcular el coeficiente de variación\n",
        "df_historico['CV'] = df_historico['Std_Dev'] / df_historico.mean(axis=1)\n",
        "\n",
        "# Asignar categorías XYZ\n",
        "df_historico['XYZ_Category'] = pd.cut(df_historico['CV'], bins=[0, 0.1, 0.25, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# Combinar las clasificaciones ABC y XYZ\n",
        "df_combined = df_forecast[['SKU', 'ABC_Category']].merge(df_historico[['SKU', 'XYZ_Category']], on='SKU')\n",
        "\n",
        "# Optimización de inventarios (ejemplo básico)\n",
        "# Calcular el stock de seguridad basado en la clasificación ABC-XYZ\n",
        "df_combined['Stock_Safety'] = df_combined.apply(lambda row:\n",
        "    df_leadtime.loc[df_leadtime['SKU'] == row['SKU'], 'LeadTime'].values[0] * df_historico.loc[df_historico['SKU'] == row['SKU'], 'Std_Dev'].values[0] *\n",
        "    (1 + (row['ABC_Category'] == 'A') * 0.5 + (row['ABC_Category'] == 'B') * 0.3 + (row['ABC_Category'] == 'C') * 0.1), axis=1)\n",
        "\n",
        "# Guardar los resultados en un archivo Excel\n",
        "with pd.ExcelWriter('resultados_clasificacion_optimizacion.xlsx') as writer:\n",
        "    df_combined.to_excel(writer, sheet_name='Clasificacion_ABC_XYZ', index=False)\n",
        "    df_combined[['SKU', 'Stock_Safety']].to_excel(writer, sheet_name='Optimizacion_Inventario', index=False)\n",
        "\n",
        "print(\"Proceso completado. Los resultados se han guardado en 'resultados_clasificacion_optimizacion.xlsx'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "QL1OBGUoAH5-",
        "outputId": "34e074ff-cab3-494a-fc5e-abc805b9c43f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['SKU'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f7c3c560fbb2>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Combinar las clasificaciones ABC y XYZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mdf_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_forecast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ABC_Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_historico\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'XYZ_Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Optimización de inventarios (ejemplo básico)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['SKU'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def convert_to_numeric(df, exclude_cols=['SKU']):\n",
        "    \"\"\"\n",
        "    Convierte todas las columnas a numéricas, excepto las especificadas en exclude_cols\n",
        "    \"\"\"\n",
        "    for col in df.columns:\n",
        "        if col not in exclude_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "    return df\n",
        "\n",
        "def load_and_clean_data(url):\n",
        "    \"\"\"\n",
        "    Carga los datos de todas las hojas y las limpia\n",
        "    \"\"\"\n",
        "    # Cargar todas las hojas\n",
        "    lead_time = pd.read_excel(url, sheet_name='LeadTime-Dias')\n",
        "    historico = pd.read_excel(url, sheet_name='Historico')\n",
        "    forecast = pd.read_excel(url, sheet_name='Forecast')\n",
        "    precios = pd.read_excel(url, sheet_name='Precios-Costos')\n",
        "\n",
        "    # Limpiar cada DataFrame\n",
        "    lead_time = convert_to_numeric(lead_time)\n",
        "    historico = convert_to_numeric(historico)\n",
        "    forecast = convert_to_numeric(forecast)\n",
        "    precios = convert_to_numeric(precios)\n",
        "\n",
        "    return lead_time, historico, forecast, precios\n",
        "\n",
        "def clasificacion_abc(forecast_df, precios_df):\n",
        "    \"\"\"\n",
        "    Realiza la clasificación ABC basada en el valor total de ventas\n",
        "    \"\"\"\n",
        "    # Calcular ventas totales pronosticadas por SKU\n",
        "    ventas_forecast = forecast_df.set_index('SKU').sum(axis=1)\n",
        "\n",
        "    # Obtener precios por SKU\n",
        "    precios = precios_df.set_index('SKU')['Precio']\n",
        "\n",
        "    # Calcular valor total\n",
        "    valor_total = ventas_forecast * precios\n",
        "\n",
        "    # Ordenar de mayor a menor\n",
        "    valor_total_sorted = valor_total.sort_values(ascending=False)\n",
        "\n",
        "    # Calcular porcentaje acumulado\n",
        "    porcentaje_acumulado = (valor_total_sorted.cumsum() / valor_total_sorted.sum()) * 100\n",
        "\n",
        "    # Asignar categorías ABC\n",
        "    def get_categoria_abc(porcentaje):\n",
        "        if porcentaje <= 60:\n",
        "            return 'A'\n",
        "        elif porcentaje <= 80:\n",
        "            return 'B'\n",
        "        else:\n",
        "            return 'C'\n",
        "\n",
        "    categorias_abc = porcentaje_acumulado.apply(get_categoria_abc)\n",
        "\n",
        "    # Crear DataFrame con resultados\n",
        "    resultados_abc = pd.DataFrame({\n",
        "        'SKU': categorias_abc.index,\n",
        "        'Valor_Total': valor_total_sorted,\n",
        "        'Porcentaje_Acumulado': porcentaje_acumulado,\n",
        "        'Categoria_ABC': categorias_abc\n",
        "    })\n",
        "\n",
        "    return resultados_abc\n",
        "\n",
        "def main():\n",
        "    # URL del archivo\n",
        "    url = \"https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx\"\n",
        "\n",
        "    # Cargar y limpiar datos\n",
        "    lead_time, historico, forecast, precios = load_and_clean_data(url)\n",
        "\n",
        "    # Realizar clasificación ABC\n",
        "    resultados_abc = clasificacion_abc(forecast, precios)\n",
        "\n",
        "    return resultados_abc\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resultados = main()"
      ],
      "metadata": {
        "id": "kE6geMXvAYD0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# URL del archivo Excel\n",
        "url = 'https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx'\n",
        "\n",
        "# Cargar los datos de las cuatro hojas del archivo Excel\n",
        "lead_time = pd.read_excel(url, sheet_name='LeadTime-Dias')\n",
        "historico = pd.read_excel(url, sheet_name='Historico')\n",
        "forecast = pd.read_excel(url, sheet_name='Forecast')\n",
        "precios_costos = pd.read_excel(url, sheet_name='Precios-Costos')\n",
        "\n",
        "# Función personalizada para convertir columnas a tipo numérico\n",
        "def convert_to_numeric(df, exclude_columns=['SKU']):\n",
        "    for col in df.columns:\n",
        "        if col not in exclude_columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "    return df\n",
        "\n",
        "# Limpiar y preparar los datos\n",
        "lead_time = convert_to_numeric(lead_time)\n",
        "historico = convert_to_numeric(historico)\n",
        "forecast = convert_to_numeric(forecast)\n",
        "precios_costos = convert_to_numeric(precios_costos)\n",
        "\n",
        "# Seleccionar solo las columnas numéricas para los cálculos posteriores, manteniendo 'SKU'\n",
        "lead_time_numeric = lead_time.select_dtypes(include=[np.number])\n",
        "historico_numeric = historico.select_dtypes(include=[np.number])\n",
        "forecast_numeric = forecast.select_dtypes(include=[np.number])\n",
        "precios_costos_numeric = precios_costos.select_dtypes(include=[np.number])\n",
        "\n",
        "# Clasificación ABC\n",
        "# Calcular el valor total multiplicando la suma de las ventas pronosticadas por el precio\n",
        "forecast['Total_Value'] = forecast_numeric.sum(axis=1) * precios_costos['Precio']\n",
        "\n",
        "# Calcular el porcentaje acumulado\n",
        "forecast['Cumulative_Percentage'] = forecast['Total_Value'].cumsum() / forecast['Total_Value'].sum() * 100\n",
        "\n",
        "# Asignar categorías A (0-60%), B (60-80%), C (80-100%)\n",
        "def assign_abc_category(percentage):\n",
        "    if percentage <= 60:\n",
        "        return 'A'\n",
        "    elif percentage <= 80:\n",
        "        return 'B'\n",
        "    else:\n",
        "        return 'C'\n",
        "\n",
        "forecast['ABC_Category'] = forecast['Cumulative_Percentage'].apply(assign_abc_category)\n",
        "\n",
        "# Mostrar el resultado final\n",
        "print(forecast[['SKU', 'Total_Value', 'Cumulative_Percentage', 'ABC_Category']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDkeEQtHAi6b",
        "outputId": "9f83a729-fa00-4bac-dc4c-d649ad4b50d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       SKU  Total_Value  Cumulative_Percentage ABC_Category\n",
            "0    SKU 1   2056600.61               3.830092            A\n",
            "1    SKU 2   3725423.60              10.768101            A\n",
            "2    SKU 3   3047630.92              16.443829            A\n",
            "3    SKU 4   2973709.29              21.981889            A\n",
            "4    SKU 5   1620510.82              24.999833            A\n",
            "5    SKU 6   1768272.66              28.292960            A\n",
            "6    SKU 7   1957194.51              31.937923            A\n",
            "7    SKU 8    933311.16              33.676067            A\n",
            "8    SKU 9   1691464.32              36.826150            A\n",
            "9   SKU 10   1928633.76              40.417924            A\n",
            "10  SKU 11   2645470.81              45.344693            A\n",
            "11  SKU 12   2666759.61              50.311108            A\n",
            "12  SKU 13   2103481.71              54.228508            A\n",
            "13  SKU 14   2489953.92              58.865652            A\n",
            "14  SKU 15   1191377.52              61.084403            B\n",
            "15  SKU 16   1431411.03              63.750178            B\n",
            "16  SKU 17   2292565.00              68.019716            B\n",
            "17  SKU 18   2483160.96              72.644208            B\n",
            "18  SKU 19   1015660.58              74.535715            B\n",
            "19  SKU 20    865393.10              76.147372            B\n",
            "20  SKU 21   1701006.65              79.315226            B\n",
            "21  SKU 22   1569411.27              82.238005            C\n",
            "22  SKU 23   1570836.26              85.163438            C\n",
            "23  SKU 24   1037599.92              87.095803            C\n",
            "24  SKU 25   1354738.56              89.618788            C\n",
            "25  SKU 26   1288549.89              92.018507            C\n",
            "26  SKU 27   1279993.68              94.402292            C\n",
            "27  SKU 28    810839.88              95.912352            C\n",
            "28  SKU 29   1493185.99              98.693174            C\n",
            "29  SKU 30    701711.66             100.000000            C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Función para convertir columnas a tipo numérico y llenar NaN con 0\n",
        "def convert_to_numeric_and_fillna(column):\n",
        "    return pd.to_numeric(column, errors='coerce').fillna(0)\n",
        "\n",
        "# Cargar los datos de las cuatro hojas del archivo Excel\n",
        "url = \"https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx\"\n",
        "\n",
        "# Cargar cada hoja en un DataFrame\n",
        "df_leadtime = pd.read_excel(url, sheet_name='LeadTime-Dias')\n",
        "df_historico = pd.read_excel(url, sheet_name='Historico')\n",
        "df_forecast = pd.read_excel(url, sheet_name='Forecast')\n",
        "df_precios = pd.read_excel(url, sheet_name='Precios-Costos')\n",
        "\n",
        "# Limpiar y preparar los datos\n",
        "# Convertir columnas a tipo numérico y llenar NaN con 0\n",
        "for df in [df_leadtime, df_historico, df_forecast, df_precios]:\n",
        "    for col in df.columns:\n",
        "        if col != 'SKU':\n",
        "            df[col] = convert_to_numeric_and_fillna(df[col])\n",
        "\n",
        "# Mantener la columna SKU en los DataFrames\n",
        "df_leadtime_sku = df_leadtime[['SKU']]\n",
        "df_historico_sku = df_historico[['SKU']]\n",
        "df_forecast_sku = df_forecast[['SKU']]\n",
        "df_precios_sku = df_precios[['SKU']]\n",
        "\n",
        "# Seleccionar solo las columnas numéricas para los cálculos posteriores\n",
        "df_leadtime = df_leadtime.select_dtypes(include=[np.number])\n",
        "df_historico = df_historico.select_dtypes(include=[np.number])\n",
        "df_forecast = df_forecast.select_dtypes(include=[np.number])\n",
        "df_precios = df_precios.select_dtypes(include=[np.number])\n",
        "\n",
        "# Agregar la columna SKU nuevamente a los DataFrames\n",
        "df_leadtime = pd.concat([df_leadtime_sku, df_leadtime], axis=1)\n",
        "df_historico = pd.concat([df_historico_sku, df_historico], axis=1)\n",
        "df_forecast = pd.concat([df_forecast_sku, df_forecast], axis=1)\n",
        "df_precios = pd.concat([df_precios_sku, df_precios], axis=1)\n",
        "\n",
        "# Clasificación ABC\n",
        "# Calcular el valor total multiplicando la suma de las ventas pronosticadas por el precio\n",
        "df_forecast['Total_Value'] = df_forecast.iloc[:, 1:].sum(axis=1) * df_precios.iloc[:, 1]\n",
        "\n",
        "# Calcular el porcentaje acumulado\n",
        "df_forecast['Cumulative_Percentage'] = df_forecast['Total_Value'].cumsum() / df_forecast['Total_Value'].sum() * 100\n",
        "\n",
        "# Asignar categorías ABC\n",
        "df_forecast['ABC_Category'] = pd.cut(df_forecast['Cumulative_Percentage'], bins=[0, 60, 80, 100], labels=['A', 'B', 'C'])\n",
        "\n",
        "# Clasificación XYZ\n",
        "# Calcular la desviación estándar de las ventas históricas\n",
        "df_historico['Std_Dev'] = df_historico.iloc[:, 1:].std(axis=1)\n",
        "\n",
        "# Calcular el coeficiente de variación\n",
        "df_historico['CV'] = df_historico['Std_Dev'] / df_historico.iloc[:, 1:].mean(axis=1)\n",
        "\n",
        "# Asignar categorías XYZ\n",
        "df_historico['XYZ_Category'] = pd.cut(df_historico['CV'], bins=[0, 0.1, 0.25, np.inf], labels=['X', 'Y', 'Z'])\n",
        "\n",
        "# Combinar las clasificaciones ABC y XYZ\n",
        "df_combined = df_forecast[['SKU', 'ABC_Category']].merge(df_historico[['SKU', 'XYZ_Category']], on='SKU')\n",
        "\n",
        "# Optimización de inventarios (ejemplo básico)\n",
        "# Calcular el stock de seguridad basado en la clasificación ABC-XYZ\n",
        "df_combined['Stock_Safety'] = df_combined.apply(lambda row:\n",
        "    df_leadtime.loc[df_leadtime['SKU'] == row['SKU'], 'LeadTime'].values[0] * df_historico.loc[df_historico['SKU'] == row['SKU'], 'Std_Dev'].values[0] *\n",
        "    (1 + (row['ABC_Category'] == 'A') * 0.5 + (row['ABC_Category'] == 'B') * 0.3 + (row['ABC_Category'] == 'C') * 0.1), axis=1)\n",
        "\n",
        "# Guardar los resultados en un archivo Excel\n",
        "with pd.ExcelWriter('resultados_clasificacion_optimizacion.xlsx') as writer:\n",
        "    df_combined.to_excel(writer, sheet_name='Clasificacion_ABC_XYZ', index=False)\n",
        "    df_combined[['SKU', 'Stock_Safety']].to_excel(writer, sheet_name='Optimizacion_Inventario', index=False)\n",
        "\n",
        "print(\"Proceso completado. Los resultados se han guardado en 'resultados_clasificacion_optimizacion.xlsx'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "3kxjks_VArBl",
        "outputId": "6059b629-70ff-44db-ebbe-55183ec558c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'LeadTime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'LeadTime'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0dbe15332915>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Optimización de inventarios (ejemplo básico)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Calcular el stock de seguridad basado en la clasificación ABC-XYZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m df_combined['Stock_Safety'] = df_combined.apply(lambda row: \n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mdf_leadtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_leadtime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LeadTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf_historico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_historico\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Std_Dev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     (1 + (row['ABC_Category'] == 'A') * 0.5 + (row['ABC_Category'] == 'B') * 0.3 + (row['ABC_Category'] == 'C') * 0.1), axis=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0dbe15332915>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Calcular el stock de seguridad basado en la clasificación ABC-XYZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m df_combined['Stock_Safety'] = df_combined.apply(lambda row: \n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mdf_leadtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_leadtime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LeadTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf_historico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_historico\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Std_Dev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     (1 + (row['ABC_Category'] == 'A') * 0.5 + (row['ABC_Category'] == 'B') * 0.3 + (row['ABC_Category'] == 'C') * 0.1), axis=1)\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_ellipsis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1063\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;31m# GH#5567 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4287\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4288\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'LeadTime'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def convert_to_numeric(df, exclude_cols=['SKU']):\n",
        "    \"\"\"\n",
        "    Convierte todas las columnas a numéricas, excepto las especificadas en exclude_cols\n",
        "    \"\"\"\n",
        "    for col in df.columns:\n",
        "        if col not in exclude_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "    return df\n",
        "\n",
        "def load_and_clean_data(url):\n",
        "    \"\"\"\n",
        "    Carga los datos de todas las hojas y las limpia\n",
        "    \"\"\"\n",
        "    # Cargar todas las hojas\n",
        "    lead_time = pd.read_excel(url, sheet_name='LeadTime-Dias')\n",
        "    historico = pd.read_excel(url, sheet_name='Historico')\n",
        "    forecast = pd.read_excel(url, sheet_name='Forecast')\n",
        "    precios = pd.read_excel(url, sheet_name='Precios-Costos')\n",
        "\n",
        "    # Limpiar cada DataFrame\n",
        "    lead_time = convert_to_numeric(lead_time)\n",
        "    historico = convert_to_numeric(historico)\n",
        "    forecast = convert_to_numeric(forecast)\n",
        "    precios = convert_to_numeric(precios)\n",
        "\n",
        "    return lead_time, historico, forecast, precios\n",
        "\n",
        "def clasificacion_abc(forecast_df, precios_df):\n",
        "    \"\"\"\n",
        "    Realiza la clasificación ABC basada en el valor total de ventas\n",
        "    \"\"\"\n",
        "    # Calcular ventas totales pronosticadas por SKU\n",
        "    ventas_forecast = forecast_df.set_index('SKU').sum(axis=1)\n",
        "\n",
        "    # Obtener precios por SKU\n",
        "    precios = precios_df.set_index('SKU')['Precio']\n",
        "\n",
        "    # Calcular valor total\n",
        "    valor_total = ventas_forecast * precios\n",
        "\n",
        "    # Ordenar de mayor a menor\n",
        "    valor_total_sorted = valor_total.sort_values(ascending=False)\n",
        "\n",
        "    # Calcular porcentaje acumulado\n",
        "    porcentaje_acumulado = (valor_total_sorted.cumsum() / valor_total_sorted.sum()) * 100\n",
        "\n",
        "    # Asignar categorías ABC\n",
        "    def get_categoria_abc(porcentaje):\n",
        "        if porcentaje <= 60:\n",
        "            return 'A'\n",
        "        elif porcentaje <= 80:\n",
        "            return 'B'\n",
        "        else:\n",
        "            return 'C'\n",
        "\n",
        "    categorias_abc = porcentaje_acumulado.apply(get_categoria_abc)\n",
        "\n",
        "    # Crear DataFrame con resultados\n",
        "    resultados_abc = pd.DataFrame({\n",
        "        'SKU': categorias_abc.index,\n",
        "        'Valor_Total': valor_total_sorted,\n",
        "        'Porcentaje_Acumulado': porcentaje_acumulado,\n",
        "        'Categoria_ABC': categorias_abc\n",
        "    })\n",
        "\n",
        "    return resultados_abc\n",
        "\n",
        "def mostrar_resultados(resultados_abc):\n",
        "    \"\"\"\n",
        "    Muestra los resultados de la clasificación ABC\n",
        "    \"\"\"\n",
        "    # Formatear Valor_Total y Porcentaje_Acumulado\n",
        "    resultados_abc['Valor_Total'] = resultados_abc['Valor_Total'].round(2)\n",
        "    resultados_abc['Porcentaje_Acumulado'] = resultados_abc['Porcentaje_Acumulado'].round(2)\n",
        "\n",
        "    # Mostrar los primeros registros\n",
        "    print(\"\\nPrimeros 10 registros de la clasificación ABC:\")\n",
        "    print(resultados_abc.head(10).to_string())\n",
        "\n",
        "    # Mostrar resumen por categoría\n",
        "    print(\"\\nResumen por categoría ABC:\")\n",
        "    resumen = resultados_abc.groupby('Categoria_ABC').agg({\n",
        "        'SKU': 'count',\n",
        "        'Valor_Total': 'sum'\n",
        "    }).round(2)\n",
        "\n",
        "    resumen['Porcentaje_Valor'] = (resumen['Valor_Total'] / resumen['Valor_Total'].sum() * 100).round(2)\n",
        "    resumen['Porcentaje_Items'] = (resumen['SKU'] / resumen['SKU'].sum() * 100).round(2)\n",
        "\n",
        "    print(resumen)\n",
        "\n",
        "def main():\n",
        "    # URL del archivo\n",
        "    url = \"https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx\"\n",
        "\n",
        "    # Cargar y limpiar datos\n",
        "    lead_time, historico, forecast, precios = load_and_clean_data(url)\n",
        "\n",
        "    # Realizar clasificación ABC\n",
        "    resultados_abc = clasificacion_abc(forecast, precios)\n",
        "\n",
        "    # Mostrar resultados\n",
        "    mostrar_resultados(resultados_abc)\n",
        "\n",
        "    return resultados_abc\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resultados = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNuC_UsHAz6c",
        "outputId": "cba07460-6973-439c-a476-7afcf12a7976"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeros 10 registros de la clasificación ABC:\n",
            "           SKU  Valor_Total  Porcentaje_Acumulado Categoria_ABC\n",
            "SKU                                                            \n",
            "SKU 2    SKU 2   3725423.60                  6.94             A\n",
            "SKU 3    SKU 3   3047630.92                 12.61             A\n",
            "SKU 4    SKU 4   2973709.29                 18.15             A\n",
            "SKU 12  SKU 12   2666759.61                 23.12             A\n",
            "SKU 11  SKU 11   2645470.81                 28.04             A\n",
            "SKU 14  SKU 14   2489953.92                 32.68             A\n",
            "SKU 18  SKU 18   2483160.96                 37.31             A\n",
            "SKU 17  SKU 17   2292565.00                 41.58             A\n",
            "SKU 13  SKU 13   2103481.71                 45.49             A\n",
            "SKU 1    SKU 1   2056600.61                 49.32             A\n",
            "\n",
            "Resumen por categoría ABC:\n",
            "               SKU  Valor_Total  Porcentaje_Valor  Porcentaje_Items\n",
            "Categoria_ABC                                                      \n",
            "A               13  32138857.36             59.85             43.33\n",
            "B                6   9646415.31             17.96             20.00\n",
            "C               11  11910586.98             22.18             36.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def convert_to_numeric(df, exclude_cols=['SKU']):\n",
        "    \"\"\"\n",
        "    Convierte todas las columnas a numéricas, excepto las especificadas en exclude_cols\n",
        "    \"\"\"\n",
        "    for col in df.columns:\n",
        "        if col not in exclude_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "    return df\n",
        "\n",
        "def load_and_clean_data(url):\n",
        "    \"\"\"\n",
        "    Carga los datos de todas las hojas y las limpia\n",
        "    \"\"\"\n",
        "    # Cargar todas las hojas\n",
        "    lead_time = pd.read_excel(url, sheet_name='LeadTime-Dias')\n",
        "    historico = pd.read_excel(url, sheet_name='Historico')\n",
        "    forecast = pd.read_excel(url, sheet_name='Forecast')\n",
        "    precios = pd.read_excel(url, sheet_name='Precios-Costos')\n",
        "\n",
        "    # Limpiar cada DataFrame\n",
        "    lead_time = convert_to_numeric(lead_time)\n",
        "    historico = convert_to_numeric(historico)\n",
        "    forecast = convert_to_numeric(forecast)\n",
        "    precios = convert_to_numeric(precios)\n",
        "\n",
        "    return lead_time, historico, forecast, precios\n",
        "\n",
        "def clasificacion_abc(forecast_df, precios_df):\n",
        "    \"\"\"\n",
        "    Realiza la clasificación ABC basada en el valor total de ventas\n",
        "    \"\"\"\n",
        "    # Calcular ventas totales pronosticadas por SKU\n",
        "    ventas_forecast = forecast_df.set_index('SKU').sum(axis=1)\n",
        "\n",
        "    # Obtener precios por SKU\n",
        "    precios = precios_df.set_index('SKU')['Precio']\n",
        "\n",
        "    # Calcular valor total\n",
        "    valor_total = ventas_forecast * precios\n",
        "\n",
        "    # Ordenar de mayor a menor\n",
        "    valor_total_sorted = valor_total.sort_values(ascending=False)\n",
        "\n",
        "    # Calcular porcentaje acumulado\n",
        "    porcentaje_acumulado = (valor_total_sorted.cumsum() / valor_total_sorted.sum()) * 100\n",
        "\n",
        "    # Asignar categorías ABC\n",
        "    def get_categoria_abc(porcentaje):\n",
        "        if porcentaje <= 60:\n",
        "            return 'A'\n",
        "        elif porcentaje <= 80:\n",
        "            return 'B'\n",
        "        else:\n",
        "            return 'C'\n",
        "\n",
        "    categorias_abc = porcentaje_acumulado.apply(get_categoria_abc)\n",
        "\n",
        "    # Crear DataFrame con resultados\n",
        "    resultados_abc = pd.DataFrame({\n",
        "        'SKU': categorias_abc.index,\n",
        "        'Valor_Total': valor_total_sorted,\n",
        "        'Porcentaje_Acumulado': porcentaje_acumulado,\n",
        "        'Categoria_ABC': categorias_abc\n",
        "    })\n",
        "\n",
        "    return resultados_abc\n",
        "\n",
        "def clasificacion_xyz(historico_df):\n",
        "    \"\"\"\n",
        "    Realiza la clasificación XYZ basada en el coeficiente de variación\n",
        "    \"\"\"\n",
        "    # Seleccionar solo las columnas numéricas y los últimos 18 meses\n",
        "    cols_numericas = historico_df.select_dtypes(include=[np.number]).columns[-18:]\n",
        "    datos_recientes = historico_df[['SKU'] + list(cols_numericas)]\n",
        "\n",
        "    # Calcular coeficiente de variación\n",
        "    cv = datos_recientes.set_index('SKU')[cols_numericas].apply(lambda x: x.std() / x.mean() * 100, axis=1)\n",
        "\n",
        "    # Asignar categorías XYZ usando qcut\n",
        "    categorias_xyz = pd.qcut(cv, q=3, labels=['X', 'Y', 'Z'])\n",
        "\n",
        "    # Crear DataFrame con resultados\n",
        "    resultados_xyz = pd.DataFrame({\n",
        "        'SKU': cv.index,\n",
        "        'Coef_Variacion': cv,\n",
        "        'Categoria_XYZ': categorias_xyz\n",
        "    })\n",
        "\n",
        "    return resultados_xyz\n",
        "\n",
        "def combinar_clasificaciones(abc_df, xyz_df):\n",
        "    \"\"\"\n",
        "    Combina las clasificaciones ABC y XYZ y asigna niveles de servicio\n",
        "    \"\"\"\n",
        "    # Combinar resultados\n",
        "    resultados_combinados = abc_df.merge(xyz_df, on='SKU', how='inner')\n",
        "\n",
        "    # Convertir categorías a strings y combinarlas\n",
        "    resultados_combinados['Categoria_ABC_XYZ'] = (\n",
        "        resultados_combinados['Categoria_ABC'].astype(str) +\n",
        "        resultados_combinados['Categoria_XYZ'].astype(str)\n",
        "    )\n",
        "\n",
        "    # Definir niveles de servicio\n",
        "    niveles_servicio = {\n",
        "        'AX': 0.95, 'AY': 0.90, 'AZ': 0.85,\n",
        "        'BX': 0.80, 'BY': 0.75, 'BZ': 0.70,\n",
        "        'CX': 0.65, 'CY': 0.60, 'CZ': 0.55\n",
        "    }\n",
        "\n",
        "    # Asignar niveles de servicio\n",
        "    resultados_combinados['Nivel_Servicio'] = (\n",
        "        resultados_combinados['Categoria_ABC_XYZ'].map(niveles_servicio)\n",
        "    )\n",
        "\n",
        "    return resultados_combinados\n",
        "\n",
        "def mostrar_resultados(resultados_combinados):\n",
        "    \"\"\"\n",
        "    Muestra los resultados de la clasificación ABC-XYZ\n",
        "    \"\"\"\n",
        "    # Formatear columnas numéricas\n",
        "    resultados_combinados['Valor_Total'] = resultados_combinados['Valor_Total'].round(2)\n",
        "    resultados_combinados['Porcentaje_Acumulado'] = resultados_combinados['Porcentaje_Acumulado'].round(2)\n",
        "    resultados_combinados['Coef_Variacion'] = resultados_combinados['Coef_Variacion'].round(2)\n",
        "\n",
        "    # Mostrar los primeros registros\n",
        "    print(\"\\nPrimeros 10 registros de la clasificación ABC-XYZ:\")\n",
        "    print(resultados_combinados.head(10).to_string())\n",
        "\n",
        "    # Mostrar resumen por categoría combinada\n",
        "    print(\"\\nResumen por categoría ABC-XYZ:\")\n",
        "    resumen = resultados_combinados.groupby('Categoria_ABC_XYZ').agg({\n",
        "        'SKU': 'count',\n",
        "        'Valor_Total': 'sum',\n",
        "        'Nivel_Servicio': 'first'\n",
        "    }).round(2)\n",
        "\n",
        "    resumen['Porcentaje_Items'] = (resumen['SKU'] / resumen['SKU'].sum() * 100).round(2)\n",
        "    resumen['Porcentaje_Valor'] = (resumen['Valor_Total'] / resumen['Valor_Total'].sum() * 100).round(2)\n",
        "\n",
        "    print(resumen)\n",
        "\n",
        "def main():\n",
        "    # URL del archivo\n",
        "    url = \"https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx\"\n",
        "\n",
        "    # Cargar y limpiar datos\n",
        "    lead_time, historico, forecast, precios = load_and_clean_data(url)\n",
        "\n",
        "    # Realizar clasificaciones\n",
        "    resultados_abc = clasificacion_abc(forecast, precios)\n",
        "    resultados_xyz = clasificacion_xyz(historico)\n",
        "\n",
        "    # Combinar clasificaciones\n",
        "    resultados_finales = combinar_clasificaciones(resultados_abc, resultados_xyz)\n",
        "\n",
        "    # Mostrar resultados\n",
        "    mostrar_resultados(resultados_finales)\n",
        "\n",
        "    return resultados_finales\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resultados = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "IZpwv-kfBiIB",
        "outputId": "a6276de4-e480-485b-932f-a0f94aae89b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'SKU' is both an index level and a column label, which is ambiguous.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4802acba0187>\u001b[0m in \u001b[0;36m<cell line: 167>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mresultados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-4802acba0187>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Combinar clasificaciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mresultados_finales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombinar_clasificaciones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultados_abc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultados_xyz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m# Mostrar resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-4802acba0187>\u001b[0m in \u001b[0;36mcombinar_clasificaciones\u001b[0;34m(abc_df, xyz_df)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \"\"\"\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Combinar resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mresultados_combinados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SKU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Convertir categorías a strings y combinarlas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_label_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_label_or_level_ambiguity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_label_or_level_ambiguity\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1866\u001b[0m                 \u001b[0;34mf\"{label_article} {label_type} label, which is ambiguous.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m             )\n\u001b[0;32m-> 1868\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'SKU' is both an index level and a column label, which is ambiguous."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def convert_to_numeric(df, exclude_cols=['SKU']):\n",
        "    \"\"\"\n",
        "    Convierte todas las columnas a numéricas, excepto las especificadas en exclude_cols\n",
        "    \"\"\"\n",
        "    for col in df.columns:\n",
        "        if col not in exclude_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "    return df\n",
        "\n",
        "def load_and_clean_data(url):\n",
        "    \"\"\"\n",
        "    Carga los datos de todas las hojas y las limpia\n",
        "    \"\"\"\n",
        "    # Cargar todas las hojas\n",
        "    lead_time = pd.read_excel(url, sheet_name='LeadTime-Dias')\n",
        "    historico = pd.read_excel(url, sheet_name='Historico')\n",
        "    forecast = pd.read_excel(url, sheet_name='Forecast')\n",
        "    precios = pd.read_excel(url, sheet_name='Precios-Costos')\n",
        "\n",
        "    # Limpiar cada DataFrame\n",
        "    lead_time = convert_to_numeric(lead_time)\n",
        "    historico = convert_to_numeric(historico)\n",
        "    forecast = convert_to_numeric(forecast)\n",
        "    precios = convert_to_numeric(precios)\n",
        "\n",
        "    return lead_time, historico, forecast, precios\n",
        "\n",
        "def clasificacion_abc(forecast_df, precios_df):\n",
        "    \"\"\"\n",
        "    Realiza la clasificación ABC basada en el valor total de ventas\n",
        "    \"\"\"\n",
        "    # Crear copia de los DataFrames para evitar modificar los originales\n",
        "    forecast = forecast_df.copy()\n",
        "    precios = precios_df.copy()\n",
        "\n",
        "    # Calcular ventas totales pronosticadas por SKU\n",
        "    forecast.set_index('SKU', inplace=True)\n",
        "    ventas_forecast = forecast.sum(axis=1)\n",
        "\n",
        "    # Obtener precios por SKU\n",
        "    precios.set_index('SKU', inplace=True)\n",
        "    precios_serie = precios['Precio']\n",
        "\n",
        "    # Calcular valor total\n",
        "    valor_total = ventas_forecast * precios_serie\n",
        "\n",
        "    # Ordenar de mayor a menor\n",
        "    valor_total_sorted = valor_total.sort_values(ascending=False)\n",
        "\n",
        "    # Calcular porcentaje acumulado\n",
        "    porcentaje_acumulado = (valor_total_sorted.cumsum() / valor_total_sorted.sum() * 100)\n",
        "\n",
        "    # Asignar categorías ABC\n",
        "    def get_categoria_abc(porcentaje):\n",
        "        if porcentaje <= 60:\n",
        "            return 'A'\n",
        "        elif porcentaje <= 80:\n",
        "            return 'B'\n",
        "        else:\n",
        "            return 'C'\n",
        "\n",
        "    categorias_abc = porcentaje_acumulado.apply(get_categoria_abc)\n",
        "\n",
        "    # Crear DataFrame con resultados\n",
        "    resultados_abc = pd.DataFrame({\n",
        "        'Valor_Total': valor_total_sorted,\n",
        "        'Porcentaje_Acumulado': porcentaje_acumulado,\n",
        "        'Categoria_ABC': categorias_abc\n",
        "    })\n",
        "\n",
        "    # Agregar SKU como columna\n",
        "    resultados_abc['SKU'] = resultados_abc.index\n",
        "    resultados_abc.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return resultados_abc\n",
        "\n",
        "def clasificacion_xyz(historico_df):\n",
        "    \"\"\"\n",
        "    Realiza la clasificación XYZ basada en el coeficiente de variación\n",
        "    \"\"\"\n",
        "    # Crear copia del DataFrame\n",
        "    historico = historico_df.copy()\n",
        "\n",
        "    # Seleccionar solo las columnas numéricas y los últimos 18 meses\n",
        "    cols_numericas = historico.select_dtypes(include=[np.number]).columns[-18:]\n",
        "    historico.set_index('SKU', inplace=True)\n",
        "\n",
        "    # Calcular coeficiente de variación\n",
        "    cv = historico[cols_numericas].apply(lambda x: x.std() / x.mean() * 100 if x.mean() != 0 else float('inf'), axis=1)\n",
        "\n",
        "    # Asignar categorías XYZ usando qcut\n",
        "    categorias_xyz = pd.qcut(cv, q=3, labels=['X', 'Y', 'Z'])\n",
        "\n",
        "    # Crear DataFrame con resultados\n",
        "    resultados_xyz = pd.DataFrame({\n",
        "        'Coef_Variacion': cv,\n",
        "        'Categoria_XYZ': categorias_xyz\n",
        "    })\n",
        "\n",
        "    # Agregar SKU como columna\n",
        "    resultados_xyz['SKU'] = resultados_xyz.index\n",
        "    resultados_xyz.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return resultados_xyz\n",
        "\n",
        "def combinar_clasificaciones(abc_df, xyz_df):\n",
        "    \"\"\"\n",
        "    Combina las clasificaciones ABC y XYZ y asigna niveles de servicio\n",
        "    \"\"\"\n",
        "    # Combinar resultados\n",
        "    resultados_combinados = pd.merge(abc_df, xyz_df, on='SKU', how='inner')\n",
        "\n",
        "    # Convertir categorías a strings y combinarlas\n",
        "    resultados_combinados['Categoria_ABC_XYZ'] = (\n",
        "        resultados_combinados['Categoria_ABC'].astype(str) +\n",
        "        resultados_combinados['Categoria_XYZ'].astype(str)\n",
        "    )\n",
        "\n",
        "    # Definir niveles de servicio\n",
        "    niveles_servicio = {\n",
        "        'AX': 0.95, 'AY': 0.90, 'AZ': 0.85,\n",
        "        'BX': 0.80, 'BY': 0.75, 'BZ': 0.70,\n",
        "        'CX': 0.65, 'CY': 0.60, 'CZ': 0.55\n",
        "    }\n",
        "\n",
        "    # Asignar niveles de servicio\n",
        "    resultados_combinados['Nivel_Servicio'] = (\n",
        "        resultados_combinados['Categoria_ABC_XYZ'].map(niveles_servicio)\n",
        "    )\n",
        "\n",
        "    return resultados_combinados\n",
        "\n",
        "def mostrar_resultados(resultados_combinados):\n",
        "    \"\"\"\n",
        "    Muestra los resultados de la clasificación ABC-XYZ\n",
        "    \"\"\"\n",
        "    # Formatear columnas numéricas\n",
        "    resultados_combinados['Valor_Total'] = resultados_combinados['Valor_Total'].round(2)\n",
        "    resultados_combinados['Porcentaje_Acumulado'] = resultados_combinados['Porcentaje_Acumulado'].round(2)\n",
        "    resultados_combinados['Coef_Variacion'] = resultados_combinados['Coef_Variacion'].round(2)\n",
        "\n",
        "    # Mostrar los primeros registros\n",
        "    print(\"\\nPrimeros 10 registros de la clasificación ABC-XYZ:\")\n",
        "    print(resultados_combinados.head(10).to_string())\n",
        "\n",
        "    # Mostrar resumen por categoría combinada\n",
        "    print(\"\\nResumen por categoría ABC-XYZ:\")\n",
        "    resumen = resultados_combinados.groupby('Categoria_ABC_XYZ').agg({\n",
        "        'SKU': 'count',\n",
        "        'Valor_Total': 'sum',\n",
        "        'Nivel_Servicio': 'first'\n",
        "    }).round(2)\n",
        "\n",
        "    resumen['Porcentaje_Items'] = (resumen['SKU'] / resumen['SKU'].sum() * 100).round(2)\n",
        "    resumen['Porcentaje_Valor'] = (resumen['Valor_Total'] / resumen['Valor_Total'].sum() * 100).round(2)\n",
        "\n",
        "    print(resumen)\n",
        "\n",
        "def main():\n",
        "    # URL del archivo\n",
        "    url = \"https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx\"\n",
        "\n",
        "    # Cargar y limpiar datos\n",
        "    lead_time, historico, forecast, precios = load_and_clean_data(url)\n",
        "\n",
        "    # Realizar clasificaciones\n",
        "    resultados_abc = clasificacion_abc(forecast, precios)\n",
        "    resultados_xyz = clasificacion_xyz(historico)\n",
        "\n",
        "    # Combinar clasificaciones\n",
        "    resultados_finales = combinar_clasificaciones(resultados_abc, resultados_xyz)\n",
        "\n",
        "    # Mostrar resultados\n",
        "    mostrar_resultados(resultados_finales)\n",
        "\n",
        "    return resultados_finales\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resultados = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4YoG-a0B0JF",
        "outputId": "185965cc-a364-452f-9a21-0d9ab9558f35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeros 10 registros de la clasificación ABC-XYZ:\n",
            "   Valor_Total  Porcentaje_Acumulado Categoria_ABC     SKU  Coef_Variacion Categoria_XYZ Categoria_ABC_XYZ  Nivel_Servicio\n",
            "0   3725423.60                  6.94             A   SKU 2           16.25             X                AX            0.95\n",
            "1   3047630.92                 12.61             A   SKU 3           17.16             X                AX            0.95\n",
            "2   2973709.29                 18.15             A   SKU 4           16.61             X                AX            0.95\n",
            "3   2666759.61                 23.12             A  SKU 12           18.85             Y                AY            0.90\n",
            "4   2645470.81                 28.04             A  SKU 11           16.81             X                AX            0.95\n",
            "5   2489953.92                 32.68             A  SKU 14           18.62             Y                AY            0.90\n",
            "6   2483160.96                 37.31             A  SKU 18           27.37             Z                AZ            0.85\n",
            "7   2292565.00                 41.58             A  SKU 17           18.64             Y                AY            0.90\n",
            "8   2103481.71                 45.49             A  SKU 13           17.94             Y                AY            0.90\n",
            "9   2056600.61                 49.32             A   SKU 1           18.73             Y                AY            0.90\n",
            "\n",
            "Resumen por categoría ABC-XYZ:\n",
            "                   SKU  Valor_Total  Nivel_Servicio  Porcentaje_Items  \\\n",
            "Categoria_ABC_XYZ                                                       \n",
            "AX                   7  18046335.55            0.95             23.33   \n",
            "AY                   5  11609360.85            0.90             16.67   \n",
            "AZ                   1   2483160.96            0.85              3.33   \n",
            "BX                   2   3311975.14            0.80              6.67   \n",
            "BZ                   4   6334440.17            0.70             13.33   \n",
            "CX                   1    933311.16            0.65              3.33   \n",
            "CY                   5   6206992.70            0.60             16.67   \n",
            "CZ                   5   4770283.12            0.55             16.67   \n",
            "\n",
            "                   Porcentaje_Valor  \n",
            "Categoria_ABC_XYZ                    \n",
            "AX                            33.61  \n",
            "AY                            21.62  \n",
            "AZ                             4.62  \n",
            "BX                             6.17  \n",
            "BZ                            11.80  \n",
            "CX                             1.74  \n",
            "CY                            11.56  \n",
            "CZ                             8.88  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# [Mantener todas las funciones anteriores hasta combinar_clasificaciones() sin cambios]\n",
        "\n",
        "def calcular_estadisticas_demanda(historico_df):\n",
        "    \"\"\"\n",
        "    Calcula estadísticas de demanda usando los últimos 18 meses\n",
        "    \"\"\"\n",
        "    # Seleccionar solo columnas numéricas de los últimos 18 meses\n",
        "    columnas_numericas = historico_df.select_dtypes(include=[np.number]).columns[-18:]\n",
        "\n",
        "    # Calcular estadísticas\n",
        "    demanda_promedio = historico_df[columnas_numericas].mean(axis=1)\n",
        "    demanda_std = historico_df[columnas_numericas].std(axis=1)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'SKU': historico_df['SKU'],\n",
        "        'Demanda_Promedio': demanda_promedio,\n",
        "        'Demanda_Std': demanda_std\n",
        "    })\n",
        "\n",
        "def calcular_estadisticas_leadtime(leadtime_df):\n",
        "    \"\"\"\n",
        "    Calcula estadísticas de lead time y convierte a meses\n",
        "    \"\"\"\n",
        "    # Seleccionar solo columnas numéricas\n",
        "    columnas_numericas = leadtime_df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "    # Calcular estadísticas\n",
        "    lt_promedio = leadtime_df[columnas_numericas].mean(axis=1) / 30  # Convertir a meses\n",
        "    lt_std = leadtime_df[columnas_numericas].std(axis=1) / 30  # Convertir a meses\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'SKU': leadtime_df['SKU'],\n",
        "        'LeadTime_Promedio': lt_promedio,\n",
        "        'LeadTime_Std': lt_std\n",
        "    })\n",
        "\n",
        "def optimizar_inventarios(demanda_stats, leadtime_stats, resultados_combinados):\n",
        "    \"\"\"\n",
        "    Calcula niveles óptimos de inventario\n",
        "    \"\"\"\n",
        "    # Combinar todas las estadísticas\n",
        "    df = pd.merge(resultados_combinados, demanda_stats, on='SKU')\n",
        "    df = pd.merge(df, leadtime_stats, on='SKU')\n",
        "\n",
        "    # Calcular Z-score basado en nivel de servicio\n",
        "    df['Z_Score'] = df['Nivel_Servicio'].apply(lambda x: stats.norm.ppf(x))\n",
        "\n",
        "    # Calcular Stock de Seguridad en días\n",
        "    df['SsDias'] = (\n",
        "        df['Z_Score'] *\n",
        "        np.sqrt(\n",
        "            df['LeadTime_Promedio'] * df['Demanda_Std']**2 +\n",
        "            df['Demanda_Promedio']**2 * df['LeadTime_Std']**2 +\n",
        "            0.5/30 * df['Demanda_Std']**2\n",
        "        ) / df['Demanda_Promedio'] * 30\n",
        "    )\n",
        "\n",
        "    # Calcular Techo de inventario en días\n",
        "    df['TechoDias'] = df['SsDias'] + df['LeadTime_Promedio'] * 30\n",
        "\n",
        "    # Calcular Nivel óptimo de inventario en días\n",
        "    df['OptimoDias'] = df['SsDias'] + (df['LeadTime_Promedio'] * 30) / 2\n",
        "\n",
        "    return df\n",
        "\n",
        "def mostrar_resultados_finales(df):\n",
        "    \"\"\"\n",
        "    Muestra los resultados finales del análisis\n",
        "    \"\"\"\n",
        "    # Seleccionar columnas relevantes\n",
        "    columnas_mostrar = [\n",
        "        'SKU', 'Categoria_ABC_XYZ', 'Nivel_Servicio',\n",
        "        'SsDias', 'TechoDias', 'OptimoDias'\n",
        "    ]\n",
        "\n",
        "    # Formatear números\n",
        "    resultado_df = df[columnas_mostrar].copy()\n",
        "    for col in ['SsDias', 'TechoDias', 'OptimoDias']:\n",
        "        resultado_df[col] = resultado_df[col].round(1)\n",
        "\n",
        "    print(\"\\nPrimeros 10 SKUs del resultado final:\")\n",
        "    print(resultado_df.head(10).to_string())\n",
        "\n",
        "    print(\"\\nEstadísticas resumen por categoría ABC-XYZ:\")\n",
        "    resumen = df.groupby('Categoria_ABC_XYZ').agg({\n",
        "        'SsDias': 'mean',\n",
        "        'TechoDias': 'mean',\n",
        "        'OptimoDias': 'mean',\n",
        "        'SKU': 'count'\n",
        "    }).round(1)\n",
        "\n",
        "    print(resumen)\n",
        "\n",
        "    return resultado_df\n",
        "\n",
        "def main():\n",
        "    # URL del archivo\n",
        "    url = \"https://github.com/santiagonajera/Clasificacion_ABC_Python/raw/main/ventas-2024-forecast.xlsx\"\n",
        "\n",
        "    # Cargar y limpiar datos\n",
        "    lead_time, historico, forecast, precios = load_and_clean_data(url)\n",
        "\n",
        "    # Realizar clasificaciones ABC-XYZ\n",
        "    resultados_abc = clasificacion_abc(forecast, precios)\n",
        "    resultados_xyz = clasificacion_xyz(historico)\n",
        "    resultados_combinados = combinar_clasificaciones(resultados_abc, resultados_xyz)\n",
        "\n",
        "    # Calcular estadísticas\n",
        "    demanda_stats = calcular_estadisticas_demanda(historico)\n",
        "    leadtime_stats = calcular_estadisticas_leadtime(lead_time)\n",
        "\n",
        "    # Optimizar inventarios\n",
        "    resultados_finales = optimizar_inventarios(\n",
        "        demanda_stats,\n",
        "        leadtime_stats,\n",
        "        resultados_combinados\n",
        "    )\n",
        "\n",
        "    # Mostrar resultados y obtener DataFrame final\n",
        "    resultado_df = mostrar_resultados_finales(resultados_finales)\n",
        "\n",
        "    return resultado_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resultados = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy8p_vqMCbRn",
        "outputId": "85ee7c45-9081-41e2-fd8b-5f391adc3007"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeros 10 SKUs del resultado final:\n",
            "      SKU Categoria_ABC_XYZ  Nivel_Servicio  SsDias  TechoDias  OptimoDias\n",
            "0   SKU 2                AX            0.95     8.2       16.3        12.3\n",
            "1   SKU 3                AX            0.95    11.8       22.0        16.9\n",
            "2   SKU 4                AX            0.95     8.5       17.6        13.1\n",
            "3  SKU 12                AY            0.90    10.2       20.3        15.3\n",
            "4  SKU 11                AX            0.95    10.3       18.8        14.5\n",
            "5  SKU 14                AY            0.90    11.2       20.9        16.0\n",
            "6  SKU 18                AZ            0.85     9.1       20.5        14.8\n",
            "7  SKU 17                AY            0.90    11.2       21.8        16.5\n",
            "8  SKU 13                AY            0.90     9.9       19.5        14.7\n",
            "9   SKU 1                AY            0.90     6.4       14.4        10.4\n",
            "\n",
            "Estadísticas resumen por categoría ABC-XYZ:\n",
            "                   SsDias  TechoDias  OptimoDias  SKU\n",
            "Categoria_ABC_XYZ                                    \n",
            "AX                   11.1       20.7        15.9    7\n",
            "AY                    9.8       19.4        14.6    5\n",
            "AZ                    9.1       20.5        14.8    1\n",
            "BX                    6.9       17.0        11.9    2\n",
            "BZ                    5.9       18.2        12.1    4\n",
            "CX                    3.2       14.5         8.8    1\n",
            "CY                    2.2       13.0         7.6    5\n",
            "CZ                    1.3       12.2         6.7    5\n"
          ]
        }
      ]
    }
  ]
}